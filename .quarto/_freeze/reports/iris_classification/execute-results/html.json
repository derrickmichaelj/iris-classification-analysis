{
  "hash": "835e2d34fa6ff0b15734ec971d290fe3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Infering Relationships Between Iris Species and their Characteristics\nauthor: Manikanth Goud Gurujala, Aitong Wu, Siharth Malik, Derrick Jaskiel\nformat: html\ntoc: true\ntoc-depth: 3\ntoc-title: Table of Contents\nbibliography: references.bib\nexecute:\n  echo: false\njupyter:\n  kernelspec:\n    display_name: 522 Group Project Env\n    language: python\n    name: 522_group_project_env\n---\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Summary\n\nThe Iris dataset consists of 150 samples of iris flowers, divided evenly into three species: setosa, versicolor, and virginica (50 samples each). Each observation contains four continuous morphological measurements: `sepal_length`, `sepal_width`, `petal_length`, and `petal_width`. All four features are recorded in centimetres. The dataset is well structured, with no missing values, and includes a balanced class distribution across the three species. A preliminary summary of the numerical features shows that values vary substantially between species; for example, setosa flowers tend to have smaller petal lengths (around 1.4 cm), while virginica flowers exhibit much larger petal dimensions. These clear differences suggest that the dataset is suitable for classification tasks, making it an ideal test case for evaluating machine learning models. In this project, we have developed a classification model using **Logistic Regression** to predict Iris flower species. based on four measurements: sepal length, sepal width, petal length, and petal width. A baseline **DummyClassifier** produced a test accuracy of approximately 0.336 across cross-validation folds, confirming that the data is not trivially predictable and that a more sophisticated model is required. Before training the model, all numerical features were scaled using StandardScaler, ensuring that differences in measurement units did not disproportionately influence the classifier. After scaling features and performing hyperparameter tuning weith randomized search, our final **Logistic Regression classifier** achieved strong performance, with a training accuracy of 0.983 and a test accuracy of 0.933. The confusion matrix indicates that the most predicitons were correct, with only a small number of misclassifications occuring between the **versicolor** and **virginica** classes reflectiong their natural feature similarity. Overall, the model demostrated high predicive performance on unseen data, though further refinement or more advnaced model could help reduce raiming classification overlap. \n\n# Introduction\n\nA thorough understanding of the geographic distribution and traits of plants is invaluable to the development of sustainable agriculture and biodiversity conservation (@Joly_et_al_2014). Thus, as the demand for information and need for biodiversity grow, it becomes even more important that this task is one that can be performed efficiently and accurately (@Thyagharajan_Kiruba_2018). One promising method through which this could be accomplished is machine learning classification.\n\nThe goal of this project is to explore how different physical measurements of iris flowers relate to species identity and to build a classification model that can accurately predict species based on these characteristics. The Iris dataset is a well-known benchmark in machine learning because it is clean, balanced, and contains clear biological differences among species. Each flower is described by four continuous measurements—sepal length, sepal width, petal length, and petal width—and belongs to one of three species: setosa, versicolor, or virginica.\n\nBecause these measurements reflect real morphological differences, the dataset provides a natural opportunity to study the relationship between flower structure and species classification. It also allows us to evaluate and compare machine learning models in a controlled environment. In this project, we perform exploratory data analysis to understand feature distributions and correlations, then develop a predictive model using Logistic Regression. We also include a DummyClassifier as a baseline to ensure that model performance improvements are meaningful rather than accidental.\n\nFinally, we evaluate the model using cross-validation, hyperparameter tuning, and confusion-matrix diagnostics. This approach allows us to understand both how well the model learns from the training data and how reliably it generalizes to unseen samples. Overall, this project demonstrates the connection between biological measurements and species identity while providing a clear example of building, tuning, and interpreting a supervised classification model.\n\n# Methods\n\n## Data\n\nThe dataset used in this project is the classic Iris flower dataset originally collected by the British statistician and biologist Ronald A. Fisher in 1936 as part of his research on linear discriminant analysis. It is publicly available through the UCI Machine Learning Repository, where it is widely used as a benchmark dataset for classification tasks. Each row in the dataset represents physical measurements of a single iris flower, including four numerical attributes sepal length, sepal width, petal length, and petal width recorded in centimetres. Alongside these measurements, each observation is labelled with one of three species (Iris setosa, Iris versicolor, or Iris virginica), originally identified by botanists through morphological characteristics. This dataset is clean, balanced, and well-suited for evaluating machine learning classification algorithms.\n@iris_1936\n\n## Analysis\n\nIn this step, we load the Iris dataset from an online source into a pandas DataFrame. We check for missing values to ensure the dataset is complete, view the first and last few rows to get a sense of the data structure, and look at the shape and data types to understand what kind of data we are working with.\n\n::: {#tbl-description .cell tbl-cap='Summary Statistics' execution_count=10}\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>149.000000</td>\n      <td>149.000000</td>\n      <td>149.000000</td>\n      <td>149.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843624</td>\n      <td>3.059732</td>\n      <td>3.748993</td>\n      <td>1.194631</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.830851</td>\n      <td>0.436342</td>\n      <td>1.767791</td>\n      <td>0.762622</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.300000</td>\n      <td>1.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Data validation checks\n\n- Correct data file format\n  \n- Correct column names as per schema\n  \n- No empty observations\n  \n- Missingness within expected thresholds\n  \n- Correct data types for each column\n  \n- No duplicate observations\n\n- Values within expected ranges / valid categories\n\n### Insights from Data\n\nFrom the above code cells, we can see:\n\n- The dataset has 150 rows and 5 columns.\n\n- There are no missing values, so the data is complete.\n\n- The dataset contains three species: Setosa, Versicolor, and Virginica.\n\n- Petal measurements show the strongest separation between species.\n\n- Setosa is clearly distinct, while Versicolor and Virginica overlap somewhat.\n\n- Sepal measurements show smaller differences and are less useful for distinguishing species.\n\n### Scatter plot\n\nThis plot shows how the species are separated based on petal measurements. The three species form distinct clusters, indicating that these two features are good for classification. It also shows that Setosa is well-separated, while Versicolor and Virginica have some overlap.\n\n![](../results/figures/scatter_petal.png){#fig-scatter_petal width=80%}\n\n### Boxplots\n\nThese plots show the distribution of each feature for different species. By comparing medians and ranges, we see that Setosa generally has smaller petals and sepals, while Virginica has the largest. This helps us understand the differences between species and why some features are better for classification.\n\n![](../results/figures/boxplots.png){#fig-boxplots width=60%}\n\n### Correlation Heatmap\n\nThis plot shows how the numeric features are related to each other. We can see that petal length and petal width are highly correlated, while sepal length and sepal width have a weaker correlation. This suggests that petal measurements might be more useful for distinguishing species.\n\n![](../results/figures/correlation_heatmap.png){#fig-correlation_heatmap width=60%}\n\n# Results & Discussion\n\nIn our EDA, we observed in @fig-scatter_petal and @fig-boxplots that though the pedal attributes (length and width) show a higher level of interspecies distinction than the sepal attributes, all features exhibit an adequate amount of spread to be considered useful for our model. Additionally, @fig-correlation_heatmap shows that sepal attributes are indeed correlated with petal attributes, increasing their utility to our model. After finding no conclusive evidence in support of dropping features from our model, we move forward with the full set of features from the dataset.\n\nThe next step of the process consists of splitting the data into train and test. In this case a 80-20% split is being considered.\n\nAs a precautinary step, it is always beneficial to run the dummy model on the data to get the baseline accuracy. This aids in tuning the true regression model being used for training and prediction so that a balanced train-test score can be achieved.\n\n::: {#tbl-dummy .cell tbl-cap='Dummy Classifier CV Results' execution_count=11}\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001773</td>\n      <td>0.001214</td>\n      <td>0.333333</td>\n      <td>0.336842</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001351</td>\n      <td>0.001145</td>\n      <td>0.333333</td>\n      <td>0.347368</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.002616</td>\n      <td>0.001007</td>\n      <td>0.333333</td>\n      <td>0.347368</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001872</td>\n      <td>0.001668</td>\n      <td>0.333333</td>\n      <td>0.347368</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001209</td>\n      <td>0.001253</td>\n      <td>0.347826</td>\n      <td>0.343750</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAs is seen in @tbl-dummy, the dummy model is quite ineffective when it comes to prediction in this case. This model predicts the same class each time and our data contains three classes that occur at similar frequencies. Thus, we can conclude that this is insufficient for fitting our data and begin the process of constructing a more complex model.\n\nIn order to insert all the columns that require column transformations such as the StandardScaler(), we need to obtain all the feature columns from the dataset\n\nThe preprocessor is required and is a good practice before using the pipeline. The preprocessor consists of all the required transformations and the features on which they will be performed. We employ a classification model utilizing Logistic Regresison for this task, as we have a relatively small number of features in our model. This will also allow us to retain a higher level of interpretability in our model.\n\nTo optimize the model’s classification capabilities, we employ a randomized hyperparameter search. This will provide insight into what values of the C hyperparameter from logistic regression will perform best in our model.\n\n::: {#tbl-random_search .cell tbl-cap='Top Randomized Search Hyperparameters' execution_count=12}\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>param_classifier__C</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>14.062606</td>\n      <td>0.983333</td>\n      <td>0.020412</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>78253.381859</td>\n      <td>0.975000</td>\n      <td>0.020412</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>8108.175729</td>\n      <td>0.975000</td>\n      <td>0.020412</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.712861</td>\n      <td>0.975000</td>\n      <td>0.033333</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>620.951562</td>\n      <td>0.975000</td>\n      <td>0.020412</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.905181</td>\n      <td>0.975000</td>\n      <td>0.033333</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.054645</td>\n      <td>0.975000</td>\n      <td>0.033333</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3.753517</td>\n      <td>0.975000</td>\n      <td>0.033333</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>3.621417</td>\n      <td>0.975000</td>\n      <td>0.033333</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>301.128937</td>\n      <td>0.975000</td>\n      <td>0.020412</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe see that most of our highest-performing models have a C hyperparameter value in the rough range of 1.75 to 3.75, signalling that this is our optimal range. Next, we will test our optimized model on our testing data from our initial train/test data split, allowing us to observe how well our model generalizes to unseen data.\n\n::: {#c6f40bdb .cell execution_count=13}\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain accuracy: 0.9831932773109243\nTest accuracy: 0.9333333333333333\n```\n:::\n:::\n\n\nFor greater context around these scores, we will plot a confusion matrix.\n\n![](../results/metrics/confusion_matrix.png){#fig-confusion_matrix width=80%}\n\nAchieving a training score of 0.983, it is evident that the model was able to learn the relationships between the four iris measurements. Additionally, the model generalizes to the unseen data quite well, yielding a test score of 0.933. While the discrepancy between the model's train and test scores elicit some concern around potential overfitting in the model, it is not large enough to overshadow its strong generalization capabilities.\n\nThese findings imply that the four measured flower characteristics are strong predictors that could reliably enhance species identification. Future questions could explore whether more complex models could grow accuracy even further or whether certain species pairs remain more difficult to separate due to particular traits. Overall, it appears that this model is well on its way to becoming a strong tool for iris identification.\n\n",
    "supporting": [
      "iris_classification_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}